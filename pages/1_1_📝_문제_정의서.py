# your_mcp_project/pages/1_1_ğŸ“_ë¬¸ì œ_ì •ì˜ì„œ.py
# (ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ìµœì¢… ë²„ì „)

import streamlit as st
import google.generativeai as genai
import json
import re

# -------------------- Gemini API ì„¤ì • --------------------
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    GEMINI_ENABLED = True
except (KeyError, AttributeError):
    st.error("â— Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Secrets'ì— API í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    GEMINI_ENABLED = False

# -------------------- í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™” --------------------
st.title("ğŸ“ ë¬¸ì œ ì •ì˜ì„œ (AI Wizard)")
st.markdown("---")

states_to_initialize = {
    'problem_definition': {
        "project_name": "", "project_goal": "", "problem_background": "", "expected_output": ""
    },
    'pd_messages': []
}
for key, value in states_to_initialize.items():
    if key not in st.session_state:
        st.session_state[key] = value

# -------------------- 1ë‹¨ê³„: ëŒ€í™”í˜• AI Wizard UI --------------------
st.header("âœ¨ 1ë‹¨ê³„: AIì™€ ëŒ€í™”í•˜ë©° í”„ë¡œì íŠ¸ êµ¬ìƒí•˜ê¸°")

# AIì˜ ì²« ì§ˆë¬¸ (ëŒ€í™” ê¸°ë¡ì´ ì—†ì„ ê²½ìš°)
if not st.session_state.pd_messages:
    st.session_state.pd_messages.append(
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! AI í”„ë¡œì íŠ¸ ê¸°íšì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."}
    )

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ëª¨ë‘ í‘œì‹œ
for message in st.session_state.pd_messages:
    with st.chat_message(message["role"], avatar="ğŸ¤–" if message["role"] == "assistant" else "ğŸ§‘â€ğŸ’»"):
        st.markdown(message["content"])

# --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë¡œì§ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„) ---
if user_prompt := st.chat_input("AIì—ê²Œ ë‹µë³€í•˜ê¸°...", disabled=not GEMINI_ENABLED):
    # 1. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ ë¨¼ì € ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— ì¦‰ì‹œ í‘œì‹œí•©ë‹ˆë‹¤.
    st.session_state.pd_messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(user_prompt)

    # 2. ê·¸ ë‹¤ìŒ, AIì˜ ì‘ë‹µì„ ìƒì„±í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤.
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("AIê°€ ë‹µë³€ì„ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                model = genai.GenerativeModel('gemini-1.5-flash')
                conversation_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.pd_messages])
                prompt_for_ai = f"""
                ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI í”„ë¡œì íŠ¸ ê¸°íš ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”.
                [ëŒ€í™” ê¸°ë¡]\n{conversation_history}\n[ë‹¹ì‹ ì˜ ë‹¤ìŒ ì‘ë‹µ]
                """
                response = model.generate_content(prompt_for_ai)
                ai_response = response.text
                st.markdown(ai_response)
                
                # 3. ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ AIì˜ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
                st.session_state.pd_messages.append({"role": "assistant", "content": ai_response})

            except Exception as e:
                error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤, AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                st.error(error_message)
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ì—¬ ë§¥ë½ì„ ìœ ì§€í•©ë‹ˆë‹¤.
                st.session_state.pd_messages.append({"role": "assistant", "content": error_message})


# -------------------- 2ë‹¨ê³„: ë¬¸ì„œ ìƒì„± ê¸°ëŠ¥ --------------------
st.markdown("---")
st.header("âœ¨ 2ë‹¨ê³„: ëŒ€í™” ë‚´ìš©ìœ¼ë¡œ ë¬¸ì„œ ì´ˆì•ˆ ìƒì„±í•˜ê¸°")

if len(st.session_state.pd_messages) > 1:
    if st.button("ğŸ’¬ ë¬¸ì„œ ì´ˆì•ˆ ìƒì„±í•˜ê¸°", type="primary", use_container_width=True, disabled=not GEMINI_ENABLED):
        with st.spinner("AIê°€ ëŒ€í™” ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ë¬¸ì„œ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤..."):
            # ... (ì´í•˜ ë¬¸ì„œ ìƒì„± ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼) ...
            model = genai.GenerativeModel('gemini-1.5-flash')
            conversation_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.pd_messages])
            
            prompt_for_json = f"""
            ë‹¹ì‹ ì€ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê³µì‹ ë¬¸ì„œë¡œ ì •ë¦¬í•˜ëŠ” ë›°ì–´ë‚œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ì•„ë˜ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ 'ë¬¸ì œ ì •ì˜ì„œ'ì˜ ê° í•­ëª©ì„ ì±„ì›Œì£¼ì„¸ìš”.
            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

            [ëŒ€í™” ê¸°ë¡]
            {conversation_history}

            ```json
            {{
                "project_name": "[í”„ë¡œì íŠ¸ì˜ íŠ¹ì„±ì„ ì˜ ë‚˜íƒ€ë‚´ëŠ” ì´ë¦„]",
                "project_goal": "[í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œ]",
                "problem_background": "[ì´ ë¬¸ì œê°€ ì™œ ì¤‘ìš”í•˜ê³  í•´ê²°í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ë°°ê²½]",
                "expected_output": "[í”„ë¡œì íŠ¸ì˜ êµ¬ì²´ì ì¸ ê²°ê³¼ë¬¼]"
            }}
            ```
            """
            try:
                response = model.generate_content(prompt_for_json)
                match = re.search(r"```json\s*(\{.*?\})\s*```", response.text, re.DOTALL)
                if match:
                    json_str = match.group(1)
                    parsed_data = json.loads(json_str)
                    st.session_state.problem_definition.update(parsed_data)
                    st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ! ì•„ë˜ 3ë‹¨ê³„ì—ì„œ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
                else:
                    st.error("AIì˜ ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON í˜•ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    st.code(response.text)
            except Exception as e:
                st.error(f"ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.rerun() # í¼ ë‚´ìš©ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ìƒˆë¡œê³ ì¹¨
else:
    st.info("AIì™€ í•œ ë²ˆ ì´ìƒ ëŒ€í™”í•´ì•¼ ë¬¸ì„œ ì´ˆì•ˆì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# -------------------- 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ í™•ì¸ ë° ì €ì¥ --------------------
st.markdown("---")
st.header("âœ¨ 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ í™•ì¸ ë° ì €ì¥í•˜ê¸°")
with st.form("problem_definition_form"):
    # ... (ì´í•˜ í¼ ê´€ë ¨ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ...
    project_name = st.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=st.session_state.problem_definition.get("project_name", ""))
    project_goal = st.text_area("í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œ", value=st.session_state.problem_definition.get("project_goal", ""), height=100)
    problem_background = st.text_area("ë¬¸ì œ ë°°ê²½ ë° í•„ìš”ì„±", value=st.session_state.problem_definition.get("problem_background", ""), height=200)
    expected_output = st.text_area("í•µì‹¬ ê²°ê³¼ë¬¼", value=st.session_state.problem_definition.get("expected_output", ""), height=100)
    
    if st.form_submit_button("ğŸ’¾ ì´ ë‚´ìš©ìœ¼ë¡œ ì €ì¥í•˜ê¸°", use_container_width=True):
        st.session_state.problem_definition.update({
            "project_name": project_name, "project_goal": project_goal,
            "problem_background": problem_background, "expected_output": output
        })
        st.success("ë¬¸ì œ ì •ì˜ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
