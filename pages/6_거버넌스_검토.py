# pages/6_ê±°ë²„ë„ŒìŠ¤_ê²€í† .py (ìë™ ê²€ì¦ ê¸°ëŠ¥ ì¶”ê°€)

import streamlit as st
import re
import yaml
# ... (ê¸°íƒ€ import)

st.title("ğŸ›¡ï¸ ê±°ë²„ë„ŒìŠ¤ ê²€ì¦ (ìë™í™”)")
st.markdown("---")

# --- 1. ë°ì´í„° ìˆ˜ì§‘ ë° ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
selected_id = st.session_state.get('selected_project_id')
if not selected_id:
    # ... í”„ë¡œì íŠ¸ ì„ íƒ ìœ ë„ ...
    st.stop()

st.header(f"í”„ë¡œì íŠ¸: {st.session_state.get('selected_project_name', 'N/A')}")

with st.spinner("í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ì‚°ì¶œë¬¼ì„ ë¶ˆëŸ¬ì™€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
    # DBì—ì„œ ëª¨ë“  ì¢…ë¥˜ì˜ ìµœì‹  ì‚°ì¶œë¬¼ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (persistence.pyì— êµ¬í˜„ í•„ìš”)
    # get_latest_artifacts_for_project(selected_id)
    artifacts = {
        "MCP_YAML": get_artifacts_for_project(selected_id, "MCP_YAML"),
        "PROBLEM_DEF": get_artifacts_for_project(selected_id, "PROBLEM_DEF"),
        "MODEL_DESIGN": get_artifacts_for_project(selected_id, "MODEL_DESIGN"),
        "PERF_REPORT": get_artifacts_for_project(selected_id, "PERF_REPORT"),
    }
    
    # ê° ì‚°ì¶œë¬¼ì—ì„œ ì •ë³´ ì¶”ì¶œ
    mcp_data = {}
    if artifacts["MCP_YAML"]:
        mcp_data = yaml.safe_load(artifacts["MCP_YAML"][0]['content']).get('mcp_context', {})
    
    problem_def_text = artifacts["PROBLEM_DEF"][0]['content'] if artifacts["PROBLEM_DEF"] else ""
    perf_report_text = artifacts["PERF_REPORT"][0]['content'] if artifacts["PERF_REPORT"] else ""

    # ì˜ˆì‹œ: ì„±ëŠ¥ ë¦¬í¬íŠ¸ì—ì„œ Accuracy ì¶”ì¶œ
    accuracy_match = re.search(r"Accuracy:\s*([0-9.]+)", perf_report_text)
    accuracy = float(accuracy_match.group(1)) if accuracy_match else None


# --- 2. ìë™ ì ê²€ ìˆ˜í–‰ ë° ê²°ê³¼ í‘œì‹œ ---
st.subheader("ìë™ ê±°ë²„ë„ŒìŠ¤ ì ê²€ ê²°ê³¼")

# Rule-based Checklist
rules = {
    "ë‹´ë‹¹ì ì§€ì • ì—¬ë¶€": bool(mcp_data.get("responsible_party")),
    "ê³ ìœ„í—˜ ëª¨ë¸ ì—¬ë¶€": mcp_data.get("risk_level", "").lower() == "high",
    "ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ (Accuracy > 0.9)": accuracy is not None and accuracy > 0.9,
    "ê°œì¸ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„±": "ê°œì¸ì •ë³´" in problem_def_text
}

passed_count = 0
failed_count = 0
for rule_name, is_passed in rules.items():
    # ì¡°ê±´ì— ë”°ë¼ í†µê³¼/ì‹¤íŒ¨/ì£¼ì˜ í‘œì‹œ
    if rule_name == "ê³ ìœ„í—˜ ëª¨ë¸ ì—¬ë¶€" and is_passed:
        st.warning(f"ğŸŸ¡ **ì£¼ì˜:** {rule_name} (ê³ ìœ„í—˜ ëª¨ë¸ë¡œ ë¶„ë¥˜ë¨)", icon="âš ï¸")
    elif is_passed:
        st.success(f"âœ… **í†µê³¼:** {rule_name}", icon="âœ”ï¸")
        passed_count += 1
    else:
        st.error(f"âŒ **ë¯¸í¡:** {rule_name}", icon="â—")
        failed_count += 1

st.metric("ì ê²€ ê²°ê³¼", f"{passed_count} / {len(rules)} ì¶©ì¡±")


# --- 3. AI ê¸°ë°˜ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ---
st.markdown("---")
st.subheader("AI ì¢…í•© ë¦¬ìŠ¤í¬ ë¶„ì„ ë¦¬í¬íŠ¸")

# ì ê²€ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ AI í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
summary_of_checks = "\n".join([f"- {name}: {'ì¶©ì¡±' if passed else 'ë¯¸í¡'}" for name, passed in rules.items()])

if st.button("ğŸ¤– ì ê²€ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
    with st.spinner("AIê°€ ì¢…í•© ë¦¬ìŠ¤í¬ ë¶„ì„ ë° ê¶Œê³ ì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤..."):
        # ì—¬ê¸°ì— ì ê²€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” gemini_agent í•¨ìˆ˜ í˜¸ì¶œ
        # ì˜ˆ: generate_governance_summary(summary_of_checks, mcp_data)
        report_text = ... 
        st.markdown(report_text)
