# your_mcp_project/pages/1_1_ğŸ“_ë¬¸ì œ_ì •ì˜ì„œ.py
# (st.chat_input ëŒ€ì‹  ì»¤ìŠ¤í…€ ì…ë ¥ì°½ì„ ì‚¬ìš©í•œ ìµœì¢… ë²„ì „)

import streamlit as st
import google.generativeai as genai
import json
import re

# -------------------- Gemini API ì„¤ì • --------------------
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    GEMINI_ENABLED = True
except (KeyError, AttributeError):
    st.error("â— Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Secrets'ì— API í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    GEMINI_ENABLED = False

# -------------------- í˜ì´ì§€ ì„¤ì • ë° ì´ˆê¸°í™” --------------------
st.title("ğŸ“ ë¬¸ì œ ì •ì˜ì„œ (AI Wizard)")
st.markdown("---")

states_to_initialize = {
    'problem_definition': {
        "project_name": "", "project_goal": "", "problem_background": "", "expected_output": ""
    },
    'pd_messages': [],
    'user_input': '' # ì‚¬ìš©ì ì…ë ¥ì„ ë‹´ì„ ì„ì‹œ state
}
for key, value in states_to_initialize.items():
    if key not in st.session_state:
        st.session_state[key] = value

# -------------------- 1ë‹¨ê³„: ëŒ€í™”í˜• AI Wizard UI --------------------
st.header("âœ¨ 1ë‹¨ê³„: AIì™€ ëŒ€í™”í•˜ë©° í”„ë¡œì íŠ¸ êµ¬ìƒí•˜ê¸°")

# ëŒ€í™” ì˜ì—­ (ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
chat_container = st.container(height=400)

with chat_container:
    # AIì˜ ì²« ì§ˆë¬¸
    if not st.session_state.pd_messages:
        st.session_state.pd_messages.append(
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! AI í”„ë¡œì íŠ¸ ê¸°íšì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”."}
        )
    
    # ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.pd_messages:
        with st.chat_message(message["role"], avatar="ğŸ¤–" if message["role"] == "assistant" else "ğŸ§‘â€ğŸ’»"):
            st.markdown(message["content"])

# --- ì»¤ìŠ¤í…€ ì±„íŒ… ì…ë ¥ì°½ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„) ---
def handle_user_input():
    user_prompt = st.session_state.user_input
    if user_prompt and GEMINI_ENABLED:
        # 1. ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì— ì¶”ê°€
        st.session_state.pd_messages.append({"role": "user", "content": user_prompt})
        
        # 2. AI ì‘ë‹µ ìƒì„±
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            conversation_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.pd_messages])
            prompt_for_ai = f"""
            ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI í”„ë¡œì íŠ¸ ê¸°íš ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”.
            [ëŒ€í™” ê¸°ë¡]\n{conversation_history}\n[ë‹¹ì‹ ì˜ ë‹¤ìŒ ì‘ë‹µ]
            """
            response = model.generate_content(prompt_for_ai)
            ai_response = response.text
        except Exception as e:
            ai_response = f"ì£„ì†¡í•©ë‹ˆë‹¤, AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        
        # 3. AI ì‘ë‹µì„ ê¸°ë¡ì— ì¶”ê°€
        st.session_state.pd_messages.append({"role": "assistant", "content": ai_response})
        
        # 4. ì…ë ¥ì°½ ë¹„ìš°ê¸°
        st.session_state.user_input = ""

# st.text_areaì™€ st.buttonì„ ê°€ë¡œë¡œ ë°°ì¹˜
col1, col2 = st.columns([4, 1])
with col1:
    st.text_area(
        "AIì—ê²Œ ë‹µë³€í•˜ê¸°", 
        key="user_input", 
        label_visibility="collapsed",
        placeholder="AIì—ê²Œ ë‹µë³€í•˜ê¸°...",
        on_change=handle_user_input # Enter í‚¤ë¡œë„ ì œì¶œë˜ë„ë¡ on_change ì½œë°± ì‚¬ìš©
    )
with col2:
    st.button("ì „ì†¡", on_click=handle_user_input, use_container_width=True, type="primary")

# --- (ì´í•˜ 2, 3ë‹¨ê³„ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ---
# -------------------- 2ë‹¨ê³„: ë¬¸ì„œ ìƒì„± ê¸°ëŠ¥ --------------------
st.markdown("---")
st.header("âœ¨ 2ë‹¨ê³„: ëŒ€í™” ë‚´ìš©ìœ¼ë¡œ ë¬¸ì„œ ì´ˆì•ˆ ìƒì„±í•˜ê¸°")

if len(st.session_state.pd_messages) > 1:
    if st.button("ğŸ’¬ ë¬¸ì„œ ì´ˆì•ˆ ìƒì„±í•˜ê¸°", type="secondary", use_container_width=True, disabled=not GEMINI_ENABLED):
        with st.spinner("AIê°€ ëŒ€í™” ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ë¬¸ì„œ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤..."):
            model = genai.GenerativeModel('gemini-1.5-flash')
            conversation_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.pd_messages])
            prompt_for_json = f"""
            ë‹¹ì‹ ì€ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê³µì‹ ë¬¸ì„œë¡œ ì •ë¦¬í•˜ëŠ” ë›°ì–´ë‚œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ì•„ë˜ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ 'ë¬¸ì œ ì •ì˜ì„œ'ì˜ ê° í•­ëª©ì„ ì±„ì›Œì£¼ì„¸ìš”.
            ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

            [ëŒ€í™” ê¸°ë¡]
            {conversation_history}

            ```json
            {{
                "project_name": "[í”„ë¡œì íŠ¸ì˜ íŠ¹ì„±ì„ ì˜ ë‚˜íƒ€ë‚´ëŠ” ì´ë¦„]",
                "project_goal": "[í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œ]",
                "problem_background": "[ì´ ë¬¸ì œê°€ ì™œ ì¤‘ìš”í•˜ê³  í•´ê²°í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ë°°ê²½]",
                "expected_output": "[í”„ë¡œì íŠ¸ì˜ êµ¬ì²´ì ì¸ ê²°ê³¼ë¬¼]"
            }}
            ```
            """
            try:
                response = model.generate_content(prompt_for_json)
                match = re.search(r"```json\s*(\{.*?\})\s*```", response.text, re.DOTALL)
                if match:
                    json_str = match.group(1)
                    parsed_data = json.loads(json_str)
                    st.session_state.problem_definition.update(parsed_data)
                    st.success("ì´ˆì•ˆ ìƒì„± ì™„ë£Œ! ì•„ë˜ 3ë‹¨ê³„ì—ì„œ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
                else:
                    st.error("AIì˜ ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON í˜•ì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    st.code(response.text)
            except Exception as e:
                st.error(f"ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.rerun()
else:
    st.info("AIì™€ í•œ ë²ˆ ì´ìƒ ëŒ€í™”í•´ì•¼ ë¬¸ì„œ ì´ˆì•ˆì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# -------------------- 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ í™•ì¸ ë° ì €ì¥ --------------------
st.markdown("---")
st.header("âœ¨ 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ í™•ì¸ ë° ì €ì¥í•˜ê¸°")
with st.form("problem_definition_form"):
    project_name = st.text_input("í”„ë¡œì íŠ¸ ì´ë¦„", value=st.session_state.problem_definition.get("project_name", ""))
    project_goal = st.text_area("í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œ", value=st.session_state.problem_definition.get("project_goal", ""), height=100)
    problem_background = st.text_area("ë¬¸ì œ ë°°ê²½ ë° í•„ìš”ì„±", value=st.session_state.problem_definition.get("problem_background", ""), height=200)
    expected_output = st.text_area("í•µì‹¬ ê²°ê³¼ë¬¼", value=st.session_state.problem_definition.get("expected_output", ""), height=100)
    
    if st.form_submit_button("ğŸ’¾ ì´ ë‚´ìš©ìœ¼ë¡œ ì €ì¥í•˜ê¸°", use_container_width=True):
        st.session_state.problem_definition.update({
            "project_name": project_name, "project_goal": project_goal,
            "problem_background": problem_background, "expected_output": expected_output
        })
        st.success("ë¬¸ì œ ì •ì˜ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
